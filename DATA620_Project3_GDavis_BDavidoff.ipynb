{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geedoubledee/data620_project3/blob/main/DATA620_Project3_GDavis_BDavidoff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA620: Project 3\n",
        "#### by Glen Davis and Brett Davidoff"
      ],
      "metadata": {
        "id": "zfoq_lFr6vbD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oo_ARn1Q0xfF"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import nltk\n",
        "from nltk.corpus import names\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import textwrap as tw"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the names dataset from NLTK and shuffle the order of the entries so that it's random."
      ],
      "metadata": {
        "id": "Oxa77qqJ98e4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load names dataset from NLTK\n",
        "nltk.download('names', quiet=True)\n",
        "male_names = [(name, 'male') for name in names.words('male.txt')]\n",
        "female_names = [(name, 'female') for name in names.words('female.txt')]\n",
        "all_names = male_names + female_names\n",
        "\n",
        "# Shuffle the dataset to ensure it's randomly ordered\n",
        "random.seed(4657)\n",
        "random.shuffle(all_names)\n",
        "ln = len(all_names)\n",
        "print(f\"\\nThe first 10 out of {ln} total entries in the shuffled names dataset:\\n\")\n",
        "wrapped = tw.fill(str(all_names[:10]))\n",
        "print(wrapped)"
      ],
      "metadata": {
        "id": "VOKKO9QY95jR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1cd5477-c567-4aa0-a527-e93789766e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The first 10 out of 7944 total entries in the shuffled names dataset:\n",
            "\n",
            "[('Iseabal', 'female'), ('Andee', 'female'), ('Englebart', 'male'),\n",
            "('Susi', 'female'), ('Row', 'female'), ('Delmar', 'male'), ('Faina',\n",
            "'female'), ('Nero', 'male'), ('Dena', 'female'), ('Crista', 'female')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a function to extract a small number of features from the entries in the names dataset: a) the last letter of the name; b) the first letter of the name; c) the count of total characters within the name; and d) the count of vowel characters within the name."
      ],
      "metadata": {
        "id": "EW-05CDYOqYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(name):\n",
        "    name = name.lower()\n",
        "    features = {\n",
        "        \"last_letter\": name[-1],\n",
        "        \"first_letter\": name[0],\n",
        "        \"length\": len(name),\n",
        "        \"num_vowels\": sum(name.count(v) for v in \"aeiou\"),\n",
        "    }\n",
        "    return features"
      ],
      "metadata": {
        "id": "Dyj9emMAjRcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply the feature extraction function to the entries in the names dataset."
      ],
      "metadata": {
        "id": "FlTG7RvsPy5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features\n",
        "features = [feature_extraction(name) for name, gender in all_names]\n",
        "print(f\"\\nExtracted features for the first 10 entries in the shuffled names dataset:\\n\")\n",
        "wrapped = tw.fill(str(features[:10]))\n",
        "print(wrapped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGPWoTZOjdm_",
        "outputId": "d1b53454-48d6-4389-a380-e4c01c1acc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracted features for the first 10 entries in the shuffled names dataset:\n",
            "\n",
            "[{'last_letter': 'l', 'first_letter': 'i', 'length': 7, 'num_vowels':\n",
            "4}, {'last_letter': 'e', 'first_letter': 'a', 'length': 5,\n",
            "'num_vowels': 3}, {'last_letter': 't', 'first_letter': 'e', 'length':\n",
            "9, 'num_vowels': 3}, {'last_letter': 'i', 'first_letter': 's',\n",
            "'length': 4, 'num_vowels': 2}, {'last_letter': 'w', 'first_letter':\n",
            "'r', 'length': 3, 'num_vowels': 1}, {'last_letter': 'r',\n",
            "'first_letter': 'd', 'length': 6, 'num_vowels': 2}, {'last_letter':\n",
            "'a', 'first_letter': 'f', 'length': 5, 'num_vowels': 3},\n",
            "{'last_letter': 'o', 'first_letter': 'n', 'length': 4, 'num_vowels':\n",
            "2}, {'last_letter': 'a', 'first_letter': 'd', 'length': 4,\n",
            "'num_vowels': 2}, {'last_letter': 'a', 'first_letter': 'c', 'length':\n",
            "6, 'num_vowels': 2}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We vectorize the features so that the categorical features are represented numerically for faster model building and testing."
      ],
      "metadata": {
        "id": "g1s3-TqKcilG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical features to numerical features\n",
        "vectorizer = DictVectorizer()\n",
        "features_vect = vectorizer.fit_transform(features).toarray()"
      ],
      "metadata": {
        "id": "LDdEzhT0TbnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We extract the response variable: the gender labels."
      ],
      "metadata": {
        "id": "K3L5CifNc5Ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels\n",
        "labels = np.array([gender for name, gender in all_names])\n",
        "print(f\"\\nLabels for the first 10 entries in the shuffled names dataset:\\n\")\n",
        "wrapped = tw.fill(str(labels[:10]))\n",
        "print(wrapped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcrTzetCSfi8",
        "outputId": "e9cb68b6-4001-4961-b709-afed1f3a0da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Labels for the first 10 entries in the shuffled names dataset:\n",
            "\n",
            "['female' 'female' 'male' 'female' 'female' 'male' 'female' 'male'\n",
            "'female' 'female']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the vectorized features and the labels into train, validate, and test sets."
      ],
      "metadata": {
        "id": "iepIshjxO1iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train_validate and test sets\n",
        "sss = ShuffleSplit(n_splits = 1, test_size = 500, random_state = 42)\n",
        "sss.get_n_splits(features_vect, labels)\n",
        "train_validate_index, test_index = next(sss.split(features_vect, labels))\n",
        "x_train_validate, x_test = features_vect[train_validate_index], features_vect[test_index]\n",
        "y_train_validate, y_test = labels[train_validate_index], labels[test_index]\n",
        "\n",
        "# Perform another split on the train_validate set\n",
        "sss = ShuffleSplit(n_splits = 1, test_size = 500, random_state = 43)\n",
        "sss.get_n_splits(x_train_validate, y_train_validate)\n",
        "train_index, validate_index = next(sss.split(x_train_validate, y_train_validate))\n",
        "x_train, x_validate = x_train_validate[train_index], x_train_validate[validate_index]\n",
        "y_train, y_validate = y_train_validate[train_index], y_train_validate[validate_index]"
      ],
      "metadata": {
        "id": "gru2uYukjYo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train a Decision Tree Classifier and a Naive Bayes Classifier, and we calculate the predictive accuracy for both models using the validate set."
      ],
      "metadata": {
        "id": "R3EUiquFfgXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Decision Tree Classifier\n",
        "classifierDT = DecisionTreeClassifier()\n",
        "classifierDT.fit(x_train, y_train)\n",
        "\n",
        "# Train a Naive Bayes Classifier\n",
        "classifierNB = GaussianNB()\n",
        "classifierNB.fit(x_train, y_train)\n",
        "\n",
        "# Evaluate DTC on the validation set\n",
        "preds_val_DT = classifierDT.predict(x_validate)\n",
        "acc_val_DT = accuracy_score(y_validate, preds_val_DT)\n",
        "print(f\"\\nDecision Tree Classifier: Validation Set Predictive Accuracy: {acc_val_DT}\")\n",
        "\n",
        "# Evaluate NBC on the validation set\n",
        "preds_val_NB = classifierNB.predict(x_validate)\n",
        "acc_val_NB = accuracy_score(y_validate, preds_val_NB)\n",
        "print(f\"Naive Bayes Classifier: Validation Set Predictive Accuracy: {acc_val_NB}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNfbpZgMZ7v-",
        "outputId": "bfe8c525-314a-447a-cba4-ef6bdce59aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree Classifier: Validation Set Predictive Accuracy: 0.776\n",
            "Naive Bayes Classifier: Validation Set Predictive Accuracy: 0.764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a small number of straightforward text features derived from the names, the Decision Tree Classifier and the Naive Bayes Classifier both have relatively strong performance. However, the Decision Tree Classifier's predictive accuracy of 78% beats the Naive Bayes Classifier's score by 1.6%.\n",
        "\n",
        " In an attempt to improve both models' predictive accuracy, we expand the feature extraction function so that it derives a wider variety of features from the names. The new features include: the ratio of vowel characters to total characters; character sequences of lengths two to four;"
      ],
      "metadata": {
        "id": "xMM57QAUtmlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase feature selection complexity\n",
        "def feature_extraction2(name):\n",
        "    name = name.lower()\n",
        "    features = feature_extraction(name)\n",
        "    features[\"vowel_to_length_ratio\"] = features[\"num_vowels\"] / features[\"length\"]\n",
        "    features[\"first_2_letters\"] = name[:2]\n",
        "    features[\"last_2_letters\"] = name[-2:]\n",
        "    features[\"first_3_letters\"] = name[:3] if features[\"length\"] > 2 else 0\n",
        "    features[\"last_3_letters\"] = name[-3:] if features[\"length\"] > 2 else 0\n",
        "    features[\"num_consonants\"] = sum(name.count(c) for c in \"bcdfghjklmnpqrstvwxyz\")\n",
        "    features[\"consonant_to_vowel_ratio\"] = features[\"num_consonants\"] / features[\"num_vowels\"] if features[\"num_vowels\"] > 0 else 0\n",
        "    for n in range(2, 5): # Add all 2- to 4-letter ngrams\n",
        "        for i in range(len(name) - n + 1):\n",
        "            ngram = name[i:i+n]\n",
        "            features[f\"{n}gram_{ngram}\"] = features.get(f\"{n}gram_{ngram}\", 0) + 1\n",
        "    return features"
      ],
      "metadata": {
        "id": "dn4vChcutpml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply the newly expanded function to the names dataset and update the train, validate, and test sets to include the new features. Importantly, we use the same indices we generated for the original splits so that the observations remain in the same order and groups. Then we refit the classifiers and calculate their new predictive accuracy scores."
      ],
      "metadata": {
        "id": "N82Nn7sllaHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and vectorize new features, then split the data again using the same indices as earlier\n",
        "features = [feature_extraction2(name) for name, gender in all_names]\n",
        "features_vect = vectorizer.fit_transform(features).toarray()\n",
        "x_train_validate, x_test = features_vect[train_validate_index], features_vect[test_index]\n",
        "y_train_validate, y_test = labels[train_validate_index], labels[test_index]\n",
        "x_train, x_validate = x_train_validate[train_index], x_train_validate[validate_index]\n",
        "y_train, y_validate = y_train_validate[train_index], y_train_validate[validate_index]\n",
        "\n",
        "# Refit the models\n",
        "classifierDT.fit(x_train, y_train)\n",
        "classifierNB.fit(x_train, y_train)\n",
        "\n",
        "# Evaluate new DTC on the validation set\n",
        "preds_val_DT = classifierDT.predict(x_validate)\n",
        "acc_val_DT = accuracy_score(y_validate, preds_val_DT)\n",
        "print(f\"\\nDecision Tree Classifier: Validation Set Predictive Accuracy: {acc_val_DT}\")\n",
        "\n",
        "# Evaluate new NBC on the validation set\n",
        "preds_val_NB = classifierNB.predict(x_validate)\n",
        "acc_val_NB = accuracy_score(y_validate, preds_val_NB)\n",
        "print(f\"Naive Bayes Classifier: Validation Set Predictive Accuracy: {acc_val_NB}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSB8Gd5s0vNb",
        "outputId": "01125b43-b55c-4099-fdaa-998c180f5672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree Classifier: Validation Set Predictive Accuracy: 0.78\n",
            "Naive Bayes Classifier: Validation Set Predictive Accuracy: 0.846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Decision Tree Classifier's performance only improved by 0.2%, but the Naive Bayess Classifier's performance improved 8.2%, and it now beats the Decision Tree Classifier by 6.4%.\n",
        "\n",
        "We take a look at the 20 most important features in the Decision Tree Classifier. Calculating feature importance for Naive Bayes Classifiers requries permutation and is unfortunately too costly computation-wise in this instance, so we skip the calculations for that model."
      ],
      "metadata": {
        "id": "CONtC5-K1DI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract feature importance estimates from the classifiers\n",
        "feature_imp_DT = classifierDT.feature_importances_\n",
        "\n",
        "# Get feature names from the DictVectorizer\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Combine names and importances\n",
        "feature_imp_DT = zip(feature_names, feature_imp_DT)\n",
        "feature_imp_DT = sorted(feature_imp_DT, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print top N most important features\n",
        "print(\"\\nTop 20 features in the Decision Tree Classifier:\\n\")\n",
        "for feature, importance in feature_imp_DT[:20]:\n",
        "    print(f\"{feature}: {importance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfSAzqiI1Dyv",
        "outputId": "65d1420a-d727-401c-a241-03ae782005cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 20 features in the Decision Tree Classifier:\n",
            "\n",
            "last_letter=a: 0.1712474982701188\n",
            "last_letter=e: 0.08568029374999002\n",
            "last_letter=i: 0.04638251628264688\n",
            "last_letter=y: 0.02285590738568853\n",
            "2gram_ly: 0.02147401260829455\n",
            "length: 0.01531039973630272\n",
            "last_3_letters=een: 0.011641215012002139\n",
            "2gram_nn: 0.01026805868668367\n",
            "num_consonants: 0.009945397238504945\n",
            "2gram_is: 0.009919731958735679\n",
            "last_2_letters=ah: 0.008816397507745918\n",
            "last_letter=l: 0.008514944404524574\n",
            "consonant_to_vowel_ratio: 0.0083677953425022\n",
            "2gram_el: 0.007128011315891874\n",
            "2gram_ne: 0.006790810682062194\n",
            "num_vowels: 0.006680710229687934\n",
            "first_letter=c: 0.006221632673721103\n",
            "2gram_be: 0.006205142364663398\n",
            "last_2_letters=yn: 0.0060674935890985306\n",
            "vowel_to_length_ratio: 0.005874865421348605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we calculate the predictive accuracy for both models on the test set."
      ],
      "metadata": {
        "id": "fSaD9AJpO9qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate new DTC on the validation set\n",
        "preds_val_DT = classifierDT.predict(x_test)\n",
        "acc_val_DT = accuracy_score(y_test, preds_val_DT)\n",
        "print(f\"\\nDecision Tree Classifier: Validation Set Predictive Accuracy: {acc_val_DT}\")\n",
        "\n",
        "# Evaluate new NBC on the validation set\n",
        "preds_val_NB = classifierNB.predict(x_test)\n",
        "acc_val_NB = accuracy_score(y_test, preds_val_NB)\n",
        "print(f\"Naive Bayes Classifier: Validation Set Predictive Accuracy: {acc_val_NB}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PUoevXVQ4DL",
        "outputId": "0bbbd211-7245-46d2-dbc5-fc4560d94d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree Classifier: Validation Set Predictive Accuracy: 0.794\n",
            "Naive Bayes Classifier: Validation Set Predictive Accuracy: 0.806\n"
          ]
        }
      ]
    }
  ]
}